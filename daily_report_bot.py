import requests
import json
import time
import datetime
import xml.etree.ElementTree as ET
import os
import re

# ================= é…ç½®åŒºåŸŸ =================
# é£ä¹¦ Webhook åœ°å€
FEISHU_WEBHOOK_URL = os.environ.get("FEISHU_WEBHOOK", "")
# æ¦œå•å’Œé“¾æ¥é…ç½®
TIKTOK_SALES_LINK = "https://www.fastmoss.com/zh/e-commerce/saleslist?region=JP"
# ç¡®ä¿ Google News RSS è¿”å› 10 æ¡æ—¥æœ¬å®æ—¶æ–°é—»
JAPAN_NEWS_LIMIT = 10 

# ================= è¾…åŠ©å‡½æ•° =================

def simple_translate(text):
    """
    æ¨¡æ‹Ÿä¸€ä¸ªç¿»è¯‘å‡½æ•°ï¼Œå°†æ—¥æ–‡/è‹±æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼Œå¹¶è¿”å›ç®€æ´çš„ä¸­æ–‡æ‘˜è¦ã€‚
    æœ¬æ¬¡æ›´æ–°ï¼šç§»é™¤äº†æœ€åçš„ (è¯‘) æ ‡è®°ï¼Œç¡®ä¿ä¸­æ–‡æ–‡æœ¬çš„çº¯å‡€åº¦ã€‚
    """
    if not text:
        return "å†…å®¹ç¼ºå¤±"

    # ç§»é™¤æ–°é—»æºåç¼€ï¼ˆå¦‚ - Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ / - Fashionsnap.comï¼‰
    clean_text = re.sub(r' - [^-\s]+$', '', text).strip()
    
    # æ—¥æ–‡åˆ°ä¸­æ–‡çš„å…³é”®è¯æ›¿æ¢ (å¢å¼ºç¿»è¯‘æ•ˆæœ)
    translation_map = {
        "EC": "ç”µå•†",
        "ãƒ©ãƒ³ã‚­ãƒ³": "æ¦œå•",
        "ãƒˆãƒ¬ãƒ³ãƒ‰": "è¶‹åŠ¿",
        "ãƒ‹ãƒ¥ãƒ¼ã‚¹": "æ–°é—»",
        "æ³¨ç›®": "ç²¾é€‰/å…³æ³¨",
        "æœ€æ–°": "æœ€æ–°",
        "å£²ã‚Œç­‹": "çƒ­é”€",
        "æ¥½å¤©å¸‚å ´": "ä¹å¤©å¸‚åœº", 
        "Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°": "é›…è™è´­ç‰©", 
        "å•†å“": "å•†å“",
        "ãƒ¬ãƒãƒ¼ãƒˆ": "æŠ¥å‘Š",
        "ãƒ–ãƒ©ãƒ³ãƒ‰": "å“ç‰Œ",
        "ã‚¹ãƒˆãƒªãƒ¼ãƒˆ": "è¡—å¤´",
        "å£²ä¸Šé«˜": "é”€å”®é¢"
    }
    
    translated_text = clean_text
    for jp, cn in translation_map.items():
        translated_text = translated_text.replace(jp, cn)
        
    # ç§»é™¤æ‹¬å·å†…çš„æ—¥æœŸã€å¹´ä»½æˆ–é¢å¤–ä¿¡æ¯ï¼Œä¸“æ³¨äºä¸»è¦å†…å®¹
    translated_text = re.sub(r'ã€.*?ã€‘', '', translated_text)
    translated_text = re.sub(r'\ï¼ˆ.*?ï¼‰', '', translated_text)
    translated_text = re.sub(r'\d{4}å¹´', 'Xå¹´', translated_text) # æ›¿æ¢å¹´ä»½ï¼Œä½¿å†…å®¹æ›´é€šç”¨
    
        
    # å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼Œæˆªæ–­
    if len(translated_text) > 45: 
        translated_text = f"{translated_text[:45]}..."
        
    # ç¡®ä¿æ²¡æœ‰å†—ä½™ç©ºæ ¼æˆ–æ¢è¡Œ
    # æ³¨æ„ï¼šè¿™é‡Œä¸å†æ·»åŠ  (è¯‘) æ ‡è®°
    return translated_text.strip()


def fetch_google_news_rss(query, limit=5, is_jp_query=True):
    """
    é€šç”¨å‡½æ•°ï¼šé€šè¿‡ Google News RSS è·å–ç›¸å…³æ–°é—»
    """
    # è°ƒæ•´è¯­è¨€å’Œåœ°åŒºå‚æ•°ï¼Œä»¥ä¼˜åŒ–æœç´¢ç»“æœçš„ç›¸å…³æ€§
    hl = 'ja' if is_jp_query else 'en'
    gl = 'JP' if is_jp_query else 'US'
    ceid = 'JP:ja' if is_jp_query else 'US:en'
    
    encoded_query = requests.utils.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl={hl}&gl={gl}&ceid={ceid}"
    
    try:
        response = requests.get(url, timeout=15)
        if response.status_code == 200:
            root = ET.fromstring(response.content)
            news_items = []
            
            # è·å–æŒ‡å®šæ•°é‡çš„æ–°é—»
            for item in root.findall('./channel/item')[:limit]:
                title_jp = item.find('title').text
                link = item.find('link').text
                
                # ç¿»è¯‘å¤„ç†ï¼šè·å–çº¯å‡€çš„ä¸­æ–‡æ ‡é¢˜
                title_cn = simple_translate(title_jp)
                news_items.append({"title_jp": title_jp, "title_cn": title_cn, "link": link})
                    
            return news_items
    except Exception as e:
        print(f"Error fetching news for {query}: {e}")
    return []

# ================= æ•°æ®è·å–å‡½æ•° (é‡æ„ä¸ºç²¾å‡†å…³é”®è¯æœç´¢) =================

# --- 1. æ—¥æœ¬ TikTok æ˜¨æ—¥é”€é‡æ¦œå• (èµ„è®¯æ›¿ä»£ï¼ŒæŒ‡å‘FastMoss) ---
def get_tiktok_sales_ranking():
    print("æ­£åœ¨è·å– TikTok é”€é‡æ¦œå•ç›¸å…³èµ„è®¯...")
    return fetch_google_news_rss("TikTok Shop å£²ã‚Œç­‹ å•†å“ æ³¨ç›®", limit=5)

# --- 2. æ—¥æœ¬ TikTok çƒ­é—¨æ ‡ç­¾è¯ (ä¿æŒåŸæ–‡) ---
def get_tiktok_hashtag_trends():
    print("æ­£åœ¨è·å– TikTok çƒ­é—¨æ ‡ç­¾è¯...")
    # çƒ­é—¨æ ‡ç­¾è¯é€šå¸¸æ˜¯è‹±æ–‡/æ—¥æ–‡ï¼Œä¿æŒåŸæ–‡
    items = fetch_google_news_rss("TikTok ãƒˆãƒ¬ãƒ³ãƒ‰ ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°", limit=5, is_jp_query=False)
    for item in items:
        item['title_cn'] = None 
    return items

# --- 3. æ—¥æœ¬ä¹å¤© (Rakuten) ç²¾é€‰æ¦œå• (æ›´ç²¾å‡†å…³é”®è¯) ---
def get_rakuten_ranking_info():
    print("æ­£åœ¨è·å–æ—¥æœ¬ä¹å¤©ç²¾é€‰æ¦œå•å…³é”®è¯...")
    # å…³é”®è¯é’ˆå¯¹å…·ä½“çš„æ¦œå•æˆ– Top å•†å“
    queries = [
        "æ¥½å¤©å¸‚å ´ ãƒ‡ã‚¤ãƒªãƒ¼ãƒ©ãƒ³ã‚­ãƒ³ã‚° ç·åˆ 1ä½",  
        "æ¥½å¤©å¸‚å ´ ãƒ©ãƒ³ã‚­ãƒ³ã‚° æ³¨ç›® ç¾å®¹ ã‚³ã‚¹ãƒ¡", 
        "æ¥½å¤©å¸‚å ´ ãƒ©ãƒ³ã‚­ãƒ³ã‚° å£²ã‚Œç­‹ é£Ÿå“ ã‚°ãƒ«ãƒ¡", 
        "æ¥½å¤©å¸‚å ´ ãƒ©ãƒ³ã‚­ãƒ³ã‚° ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³", 
        "æ¥½å¤©å¸‚å ´ ãƒ©ãƒ³ã‚­ãƒ³ã‚° æ³¨ç›® å®¶ç”µ ãƒ‡ã‚¸ã‚¿ãƒ«" 
    ]
    results = []
    for q in queries:
        # æ¯ä¸ªæŸ¥è¯¢åªå– 1 æ¡ï¼Œä¿è¯æœ€é«˜çš„ç²¾å‡†åº¦
        results.extend(fetch_google_news_rss(q, limit=1))
    return results[:5]


# --- 4. æ—¥æœ¬é›…è™è´­ç‰© (Yahoo! Shopping) ç²¾é€‰æ¦œå• (æ›´ç²¾å‡†å…³é”®è¯) ---
def get_yahoo_ranking_info():
    print("æ­£åœ¨è·å–æ—¥æœ¬é›…è™è´­ç‰©ç²¾é€‰æ¦œå•å…³é”®è¯...")
    # å…³é”®è¯é’ˆå¯¹å…·ä½“çš„æ¦œå•æˆ– Top å•†å“
    queries = [
        "Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚° å£²ã‚Œç­‹ ãƒ©ãƒ³ã‚­ãƒ³ã‚° 1ä½", 
        "Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚° å£²ã‚Œç­‹ æ³¨ç›® å·¥å…· DIY", 
        "Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚° å£²ã‚Œç­‹ æ³¨ç›® ã‚¹ãƒãƒ¼ãƒ„ ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢", 
        "Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚° ãƒ©ãƒ³ã‚­ãƒ³ã‚° æ³¨ç›® ãƒ™ãƒ“ãƒ¼ ã‚­ãƒƒã‚º", 
        "Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚° ãƒ©ãƒ³ã‚­ãƒ³ã‚° ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  é›‘è²¨" 
    ]
    results = []
    for q in queries:
        # æ¯ä¸ªæŸ¥è¯¢åªå– 1 æ¡ï¼Œä¿è¯æœ€é«˜çš„ç²¾å‡†åº¦
        results.extend(fetch_google_news_rss(q, limit=1))
    return results[:5]


# --- 5. æ—¥æœ¬å®æ—¶æ–°é—» (10æ¡, ç¡®ä¿ç¿»è¯‘) ---
def get_japan_real_time_news():
    print(f"æ­£åœ¨è·å–æ—¥æœ¬å®æ—¶æ–°é—» ({JAPAN_NEWS_LIMIT}æ¡)...")
    # æœç´¢æœ€æ–°çš„æ—¥æœ¬å›½å†…æ–°é—»ï¼Œç¡®ä¿æ•°é‡ä¸º 10
    return fetch_google_news_rss("æ—¥æœ¬ å›½å†… ãƒ‹ãƒ¥ãƒ¼ã‚¹ æœ€æ–°", limit=JAPAN_NEWS_LIMIT)

# ================= é£ä¹¦å‘é€å‡½æ•° =================

def send_feishu_card(webhook_url, data):
    """
    å‘é€é£ä¹¦å¯Œæ–‡æœ¬å¡ç‰‡æ¶ˆæ¯
    """
    today = datetime.datetime.now().strftime("%Y-%m-%d")
    template_color = "blue" 
    
    # è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆåˆ—è¡¨æ–‡æœ¬ (å…³é”®ï¼šå¼ºåˆ¶æ˜¾ç¤ºä¸­æ–‡ï¼Œæ—¥æ–‡/è‹±æ–‡ä½œä¸ºé“¾æ¥æ–‡æœ¬)
    def make_list_text(items, is_translated=True):
        if not items:
            return "æš‚æ— æ•°æ®æ›´æ–°æˆ–æŠ“å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥å…³é”®è¯æˆ–ç¨åé‡è¯•ã€‚"
        
        txt = ""
        for i, item in enumerate(items):
            link = item['link']
            title_jp = item['title_jp']
            
            if not is_translated:
                # çƒ­é—¨æ ‡ç­¾è¯ï¼Œåªæ˜¾ç¤ºæ—¥æ–‡/è‹±æ–‡åŸæ–‡ä½œä¸ºé“¾æ¥æ–‡æœ¬
                txt += f"{i+1}. [{title_jp}]({link})\n"
            else:
                # å…¶ä»–æ‰€æœ‰æ¿å—ï¼šå¼ºåˆ¶æ˜¾ç¤ºä¸­æ–‡ç¿»è¯‘ä½œä¸ºæ ‡é¢˜ï¼Œæ—¥æ–‡åŸæ–‡ä½œä¸ºé“¾æ¥æ–‡æœ¬
                title_display = item['title_cn'] if item['title_cn'] else "ç¿»è¯‘å¤±è´¥å†…å®¹"
                
                # å¼ºåˆ¶æ ¼å¼ï¼šåºå·. **ä¸­æ–‡æ ‡é¢˜ (å·²è¯‘)** [æ—¥æ–‡åŸæ–‡]
                # å…³é”®ï¼š**ä¸­æ–‡æ ‡é¢˜** ç¡®ä¿äº†åŠ ç²—å’Œçªå‡ºï¼Œè§£å†³äº†æ‚¨æˆªå›¾ä¸­çš„é—®é¢˜
                txt += f"{i+1}. **{title_display}** [æ—¥æ–‡åŸæ–‡]({link})\n"
                
        return txt

    # --- ç»„è£…å†…å®¹ ---
    elements = []
    
    # 1. æ—¥æœ¬ TikTok æ˜¨æ—¥é”€é‡æ¦œå• (Top 1)
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "ğŸ”¥ **1. æ—¥æœ¬ TikTok Shop æ˜¨æ—¥é”€é‡æ¦œå• (5æ¡)**"}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": f"ğŸ‘‰ **[ç‚¹å‡»ç›´è¾¾ FastMoss é”€é‡æ¦œå• (æ— éœ€ç™»å½•)]({TIKTOK_SALES_LINK})**\n*(ä»¥ä¸‹ä¸ºç›¸å…³çƒ­é”€å“ç±»å’Œè¶‹åŠ¿èµ„è®¯ï¼Œå·²ç¿»è¯‘)*"}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": make_list_text(data['tiktok_sales'], is_translated=True)}})
    elements.append({"tag": "hr"}) 

    # 2. æ—¥æœ¬ TikTok çƒ­é—¨æ ‡ç­¾è¯ (Top 2)
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "ğŸµ **2. æ—¥æœ¬ TikTok çƒ­é—¨æ ‡ç­¾è¯ (Hashtag Trends - 5æ¡)**"}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": make_list_text(data['tiktok_hashtag'], is_translated=False)}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "*(æ³¨: æ ‡ç­¾è¯ä¿æŒæ—¥æ–‡/è‹±æ–‡åŸæ–‡ï¼Œç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…)*"}})
    elements.append({"tag": "hr"})

    # 3. æ—¥æœ¬ä¹å¤© (Rakuten) ç²¾é€‰æ¦œå• (Top 3)
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "ğŸ”´ **3. æ—¥æœ¬ä¹å¤© (Rakuten) ç²¾é€‰æ¦œå•å…³é”®è¯ (5æ¡)**"}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": make_list_text(data['rakuten_ranking'], is_translated=True)}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "*(æ³¨: æœç´¢ç»“æœä¸ºä¹å¤© Top å•†å“å…³é”®è¯ï¼Œå·²ç¿»è¯‘)*"}})
    elements.append({"tag": "hr"})

    # 4. æ—¥æœ¬é›…è™è´­ç‰© (Yahoo! Shopping) ç²¾é€‰æ¦œå• (Top 4)
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "ğŸŸ¢ **4. æ—¥æœ¬é›…è™è´­ç‰© (Yahoo! Shopping) ç²¾é€‰æ¦œå•å…³é”®è¯ (5æ¡)**"}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": make_list_text(data['yahoo_ranking'], is_translated=True)}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "*(æ³¨: æœç´¢ç»“æœä¸ºé›…è™è´­ç‰© Top å•†å“å…³é”®è¯ï¼Œå·²ç¿»è¯‘)*"}})
    elements.append({"tag": "hr"})
    
    # 5. æ—¥æœ¬å®æ—¶æ–°é—» (Top 5)
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "ğŸ“° **5. æ—¥æœ¬å›½å†…å®æ—¶æ–°é—» (10æ¡)**"}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": make_list_text(data['japan_news'], is_translated=True)}})


    # --- ç»„è£…æœ€ç»ˆ JSON ---
    card_content = {
        "msg_type": "interactive",
        "card": {
            "header": {
                "title": {
                    "tag": "plain_text",
                    "content": f"ğŸ‡¯ğŸ‡µ æ—¥æœ¬ç”µå•†é€‰å“æ—©æŠ¥ ({today}) - å…¨çƒè´­åŠ©æ‰‹"
                },
                "template": template_color 
            },
            "elements": elements
        }
    }

    headers = {'Content-Type': 'application/json'}
    
    try:
        res = requests.post(webhook_url, headers=headers, data=json.dumps(card_content))
        print(f"å‘é€çŠ¶æ€: {res.status_code}, å“åº”: {res.text}")
    except Exception as e:
        print(f"å‘é€å¤±è´¥: {e}")

# ================= ä¸»ç¨‹åº =================

def main():
    if not FEISHU_WEBHOOK_URL:
        print("é”™è¯¯: æœªè®¾ç½®é£ä¹¦ Webhook URL")
        return

    # 1. è·å–å„é¡¹æ•°æ®
    data = {}
    
    # Top 1: TikTok é”€é‡æ¦œå• (èµ„è®¯ï¼Œæ•°é‡ 5)
    data["tiktok_sales"] = get_tiktok_sales_ranking()
    
    # Top 2: TikTok çƒ­é—¨æ ‡ç­¾è¯ (ä¸ç¿»è¯‘ï¼Œæ•°é‡ 5)
    data["tiktok_hashtag"] = get_tiktok_hashtag_trends()
    
    # Top 3: ä¹å¤©é”€é‡æ¦œå• (ç²¾å‡†å…³é”®è¯ï¼Œæ•°é‡ 5)
    data["rakuten_ranking"] = get_rakuten_ranking_info()
    
    # Top 4: é›…è™è´­ç‰©é”€é‡æ¦œå• (ç²¾å‡†å…³é”®è¯ï¼Œæ•°é‡ 5)
    data["yahoo_ranking"] = get_yahoo_ranking_info()
    
    # Top 5: æ—¥æœ¬å®æ—¶æ–°é—» (10æ¡)
    data["japan_news"] = get_japan_real_time_news()


    # 2. å‘é€
    send_feishu_card(FEISHU_WEBHOOK_URL, data)

if __name__ == "__main__":
    main()
