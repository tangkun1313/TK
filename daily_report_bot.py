import requests
import json
import time
import datetime
import xml.etree.ElementTree as ET
import os
import re

# ================= é…ç½®åŒºåŸŸ =================
# é£ä¹¦ Webhook åœ°å€
FEISHU_WEBHOOK_URL = os.environ.get("FEISHU_WEBHOOK", "")
# æ¦œå•å’Œé“¾æ¥é…ç½®
TIKTOK_SALES_LINK = "https://www.fastmoss.com/zh/e-commerce/saleslist?region=JP"
# ç¡®ä¿ Google News RSS è¿”å› 10 æ¡æ—¥æœ¬å®æ—¶æ–°é—»
JAPAN_NEWS_LIMIT = 10 

# ================= è¾…åŠ©å‡½æ•° =================

def simple_translate(text):
    """
    æ¨¡æ‹Ÿä¸€ä¸ªç¿»è¯‘å‡½æ•°ï¼Œå°†æ—¥æ–‡/è‹±æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼Œå¹¶è¿”å›ç®€æ´çš„ä¸­æ–‡æ‘˜è¦ã€‚
    æœ¬æ¬¡æ›´æ–°ï¼šå¤§è§„æ¨¡æ‰©å……æ—¥æ–‡ç”µå•†/è¶‹åŠ¿è¯æ±‡çš„ç¿»è¯‘è¯å…¸ï¼Œå¹¶æ¸…ç†æ—¥æ–‡åŠ©è¯ï¼ŒåŠ›æ±‚å®ç°â€œå…¨ä¸­æ–‡â€æ•ˆæœã€‚
    """
    if not text:
        return "å†…å®¹ç¼ºå¤±"

    # ç§»é™¤æ–°é—»æºåç¼€ï¼ˆå¦‚ - Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ / - Fashionsnap.comï¼‰
    clean_text = re.sub(r' - [^-\s]+$', '', text).strip()
    
    # === å¤§å¹…å¢å¼ºç¿»è¯‘è¯å…¸ (ä¼˜å…ˆç¿»è¯‘é•¿è¯/å¤æ‚çŸ­è¯­) ===
    translation_map = {
        # å¤æ‚çŸ­è¯­/çƒ­è¯
        "è‡ªå·±æº€è¶³å‹æ¶ˆè²»": "æ‚¦å·±æ¶ˆè´¹", 
        "æ€¥æµ®ä¸Š": "è¿…é€Ÿå´›èµ·", 
        "å£²ã‚Œç­‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°": "çƒ­é”€æ’è¡Œæ¦œ",
        "ãƒ‡ã‚¤ãƒªãƒ¼ãƒ©ãƒ³ã‚­ãƒ³ã‚°": "æ¯æ—¥æ¦œå•",
        "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ": "å®æ—¶",
        "æ–°å•†å“": "æ–°å“",
        "æˆåŠŸäº‹ä¾‹": "æˆåŠŸæ¡ˆä¾‹", 
        "ç§˜è¨£": "è¯€çª",
        "ã‚³ã‚¹ãƒ¡": "ç¾å¦†/åŒ–å¦†å“",
        "ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«ã‚±ã‚¢": "ä¸ªäººæŠ¤ç†",
        "ã‚¹ã‚­ãƒ³ã‚±ã‚¢": "çš®è‚¤æŠ¤ç†",
        "ã‚¢ãƒ‘ãƒ¬ãƒ«": "æœé¥°",
        "ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«": "ç”Ÿæ´»æ–¹å¼",
        "ãƒ‡ã‚¸ã‚¿ãƒ«": "æ•°ç ",
        "æœ€æ–°å‹•å‘": "æœ€æ–°åŠ¨æ€",
        "ãƒˆãƒƒãƒ—": "é¡¶éƒ¨",
        "ãƒ©ãƒ³ã‚­ãƒ³ã‚°å…¥ã‚Š": "è¿›å…¥æ¦œå•",
        "è²©å£²": "é”€å”®",
        "å°å£²": "é›¶å”®",
        "æˆ¦ç•¥": "æˆ˜ç•¥",

        # æ ¸å¿ƒç”µå•†è¯æ±‡
        "EC": "ç”µå•†", "ãƒ©ãƒ³ã‚­ãƒ³": "æ¦œå•", "ãƒˆãƒ¬ãƒ³ãƒ‰": "è¶‹åŠ¿", "ãƒ‹ãƒ¥ãƒ¼ã‚¹": "æ–°é—»", "æ³¨ç›®": "å…³æ³¨", 
        "æœ€æ–°": "æœ€æ–°", "å£²ã‚Œç­‹": "çƒ­é”€", "æ¥½å¤©å¸‚å ´": "ä¹å¤©å¸‚åœº", "Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°": "é›…è™è´­ç‰©", 
        "å•†å“": "å•†å“", "ãƒ¬ãƒãƒ¼ãƒˆ": "æŠ¥å‘Š", "ãƒ–ãƒ©ãƒ³ãƒ‰": "å“ç‰Œ", "ã‚¹ãƒˆãƒªãƒ¼ãƒˆ": "è¡—å¤´", "å£²ä¸Šé«˜": "é”€å”®é¢",
        "ã‚·ãƒ§ãƒƒãƒ—": "åº—é“º", "ã‚»ãƒ¼ãƒ«": "ä¿ƒé”€", "ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³": "æ´»åŠ¨",
        
        # å¸¸è§æ—¥æ–‡åŠ¨è¯/å½¢å®¹è¯/åè¯
        "ä¼¸ã³": "å¢é•¿", "å…¬é–‹": "å…¬å¸ƒ", "ç™ºè¡¨": "å‘å¸ƒ", "é–‹å‚¬": "ä¸¾è¡Œ", "å½±éŸ¿": "å½±å“", 
        "å°å…¥": "å¼•å…¥", "è§£èª¬": "è§£è¯»", "çªç ´": "çªç ´", "ç‰¹é›†": "ç‰¹è¾‘", "æ€¥ä¼¸": "æš´æ¶¨", 
        "å¥½èª¿": "åŠ¿å¤´è‰¯å¥½", "äººæ°—": "çƒ­é—¨", "è‹¥è€…": "å¹´è½»äºº", "ä¸–ä»£": "ä¸–ä»£", "ãƒ¦ãƒ¼ã‚¶ãƒ¼": "ç”¨æˆ·", 
        "ã‚«ãƒ†ã‚´ãƒª": "å“ç±»", "ã‚«ãƒ†ã‚´ãƒªãƒ¼": "å“ç±»", "å¸‚å ´": "å¸‚åœº",
        
        # å¸¸è§æ—¥æ–‡åŠ©è¯/è¿è¯ (é‡ç‚¹æ¸…ç†ï¼Œç¡®ä¿ä¸­æ–‡æµç•…)
        "ãŒ": "", "ã®": "çš„", "ã«": "åœ¨", "ã‚’": "", "ã¨": "å’Œ", "ã¸": "å‘", "ã§": "åœ¨",
        "ã¯": "", "ã‚ˆã‚Š": "æ¯”", "ã‹ã‚‰": "ä»", "ã¾ã§": "åˆ°", "ãªã©": "ç­‰", 
        "ãã—ã¦": "å¹¶ä¸”", "ã—ã‹ã—": "ä½†æ˜¯", "ãŸã‚": "å› ä¸º",
        "ã«ã¤ã„ã¦": "å…³äº", 
        "ã«é–¢ã™ã‚‹": "ç›¸å…³", 
        "ã¨ã—ã¦": "ä½œä¸º", 
        "ã«å¯¾ã™ã‚‹": "é’ˆå¯¹",
        
        # æ ‡ç‚¹ç¬¦å·æ¸…ç†
        "ã€Œ": "â€œ", "ã€": "â€", "ã€": "â€œ", "ã€": "â€",
    }
    
    translated_text = clean_text
    
    # 1. æ‰§è¡Œç¿»è¯‘æ›¿æ¢ (å…³é”®ï¼šæŒ‰ç…§é”®çš„é•¿åº¦é™åºæ’åˆ—ï¼Œç¡®ä¿é•¿è¯ä¼˜å…ˆè¢«æ›¿æ¢)
    sorted_map = dict(sorted(translation_map.items(), key=lambda item: len(item[0]), reverse=True))
    
    for jp, cn in sorted_map.items():
        translated_text = translated_text.replace(jp, cn)
        
    # 2. ç§»é™¤æ‹¬å·å†…çš„æ—¥æœŸã€å¹´ä»½æˆ–é¢å¤–ä¿¡æ¯ï¼Œä¸“æ³¨äºä¸»è¦å†…å®¹
    translated_text = re.sub(r'ã€.*?ã€‘', '', translated_text)
    translated_text = re.sub(r'\ï¼ˆ.*?ï¼‰', '', translated_text)
    translated_text = re.sub(r'\d{4}å¹´', 'Xå¹´', translated_text) 
    
    # 3. æ¸…ç†å¯èƒ½æ®‹ç•™çš„æ—¥æ–‡è¯­æ³•ç»“æ„å’Œå¤šä½™ç©ºæ ¼
    # æ›¿æ¢æ—¥æ–‡é€—å·å’Œå¥å·ä¸ºä¸­æ–‡æ ‡ç‚¹
    translated_text = re.sub(r'[ã€ã€‚]', 'ï¼Œ', translated_text).strip()
    # ç§»é™¤è¿ç»­ç©ºæ ¼
    translated_text = re.sub(r'\s+', ' ', translated_text).strip()
    
    # 4. å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼Œæˆªæ–­
    if len(translated_text) > 45: 
        translated_text = f"{translated_text[:45]}..."
        
    # 5. ç¡®ä¿æ²¡æœ‰å†—ä½™ç©ºæ ¼æˆ–æ¢è¡Œ
    return translated_text.strip()


def fetch_google_news_rss(query, limit=5, is_jp_query=True):
    """
    é€šç”¨å‡½æ•°ï¼šé€šè¿‡ Google News RSS è·å–ç›¸å…³æ–°é—»
    """
    # è°ƒæ•´è¯­è¨€å’Œåœ°åŒºå‚æ•°ï¼Œä»¥ä¼˜åŒ–æœç´¢ç»“æœçš„ç›¸å…³æ€§
    hl = 'ja' if is_jp_query else 'en'
    gl = 'JP' if is_jp_query else 'US'
    ceid = 'JP:ja' if is_jp_query else 'US:en'
    
    encoded_query = requests.utils.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl={hl}&gl={gl}&ceid={ceid}"
    
    try:
        response = requests.get(url, timeout=15)
        if response.status_code == 200:
            root = ET.fromstring(response.content)
            news_items = []
            
            # è·å–æŒ‡å®šæ•°é‡çš„æ–°é—»
            for item in root.findall('./channel/item')[:limit]:
                title_jp = item.find('title').text
                link = item.find('link').text
                
                # ç¿»è¯‘å¤„ç†ï¼šè·å–çº¯å‡€çš„ä¸­æ–‡æ ‡é¢˜
                title_cn = simple_translate(title_jp)
                news_items.append({"title_jp": title_jp, "title_cn": title_cn, "link": link})
                    
            return news_items
    except Exception as e:
        print(f"Error fetching news for {query}: {e}")
    return []

# ================= æ•°æ®è·å–å‡½æ•° (é‡æ„ä¸ºç²¾å‡†å…³é”®è¯æœç´¢) =================

# --- 1. æ—¥æœ¬ TikTok æ˜¨æ—¥é”€é‡æ¦œå• (èµ„è®¯æ›¿ä»£ï¼ŒæŒ‡å‘FastMoss) ---
def get_tiktok_sales_ranking():
    print("æ­£åœ¨è·å– TikTok é”€é‡æ¦œå•ç›¸å…³èµ„è®¯...")
    return fetch_google_news_rss("TikTok Shop å£²ã‚Œç­‹ å•†å“ æ³¨ç›®", limit=5)

# --- 2. æ—¥æœ¬ TikTok çƒ­é—¨æ ‡ç­¾è¯ (ä¿æŒåŸæ–‡) ---
def get_tiktok_hashtag_trends():
    print("æ­£åœ¨è·å– TikTok çƒ­é—¨æ ‡ç­¾è¯...")
    # çƒ­é—¨æ ‡ç­¾è¯é€šå¸¸æ˜¯è‹±æ–‡/æ—¥æ–‡ï¼Œä¿æŒåŸæ–‡
    items = fetch_google_news_rss("TikTok ãƒˆãƒ¬ãƒ³ãƒ‰ ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°", limit=5, is_jp_query=False)
    for item in items:
        item['title_cn'] = None 
    return items

# --- 3. æ—¥æœ¬ä¹å¤© (Rakuten) ç²¾é€‰æ¦œå• (æ›´ç²¾å‡†å…³é”®è¯ï¼Œæ’é™¤ç«äº‰å¯¹æ‰‹) ---
def get_rakuten_ranking_info():
    print("æ­£åœ¨è·å–æ—¥æœ¬ä¹å¤©ç²¾é€‰æ¦œå•å…³é”®è¯ (å·²æ’é™¤Amazon/Yahoo)...")
    # å…³é”®è¯é’ˆå¯¹å…·ä½“çš„æ¦œå•æˆ– Top å•†å“ï¼Œä½¿ç”¨ -æ’é™¤ç«äº‰å¯¹æ‰‹
    queries = [
        "æ¥½å¤©å¸‚å ´ ãƒ‡ã‚¤ãƒªãƒ¼ãƒ©ãƒ³ã‚­ãƒ³ã‚° ç·åˆ 1ä½ -Amazon -Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°",  
        "æ¥½å¤©å¸‚å ´ ãƒ©ãƒ³ã‚­ãƒ³ã‚° æ³¨ç›® ç¾å®¹ ã‚³ã‚¹ãƒ¡ -Amazon -Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°", 
        "æ¥½å¤©å¸‚å ´ ãƒ©ãƒ³ã‚­ãƒ³ã‚° å£²ã‚Œç­‹ é£Ÿå“ ã‚°ãƒ«ãƒ¡ -Amazon -Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°", 
        "æ¥½å¤©å¸‚å ´ ãƒ©ãƒ³ã‚­ãƒ³ã‚° ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ -Amazon -Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°", 
        "æ¥½å¤©å¸‚å ´ ãƒ©ãƒ³ã‚­ãƒ³ã‚° æ³¨ç›® å®¶ç”µ ãƒ‡ã‚¸ã‚¿ãƒ« -Amazon -Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°" 
    ]
    results = []
    for q in queries:
        # æ¯ä¸ªæŸ¥è¯¢åªå– 1 æ¡ï¼Œä¿è¯æœ€é«˜çš„ç²¾å‡†åº¦
        results.extend(fetch_google_news_rss(q, limit=1))
    return results[:5]


# --- 4. æ—¥æœ¬é›…è™è´­ç‰© (Yahoo! Shopping) ç²¾é€‰æ¦œå• (æ›´ç²¾å‡†å…³é”®è¯ï¼Œæ’é™¤ç«äº‰å¯¹æ‰‹) ---
def get_yahoo_ranking_info():
    print("æ­£åœ¨è·å–æ—¥æœ¬é›…è™è´­ç‰©ç²¾é€‰æ¦œå•å…³é”®è¯ (å·²æ’é™¤ä¹å¤©/Amazon)...")
    # å…³é”®è¯é’ˆå¯¹å…·ä½“çš„æ¦œå•æˆ– Top å•†å“ï¼Œä½¿ç”¨ -æ’é™¤ç«äº‰å¯¹æ‰‹
    queries = [
        "Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚° å£²ã‚Œç­‹ ãƒ©ãƒ³ã‚­ãƒ³ã‚° 1ä½ -æ¥½å¤©å¸‚å ´ -Amazon", 
        "Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚° å£²ã‚Œç­‹ æ³¨ç›® å·¥å…· DIY -æ¥½å¤©å¸‚å ´ -Amazon", 
        "Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚° å£²ã‚Œç­‹ æ³¨ç›® ã‚¹ãƒãƒ¼ãƒ„ ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢ -æ¥½å¤©å¸‚å ´ -Amazon", 
        "Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚° ãƒ©ãƒ³ã‚­ãƒ³ã‚° æ³¨ç›® ãƒ™ãƒ“ãƒ¼ ã‚­ãƒƒã‚º -æ¥½å¤©å¸‚å ´ -Amazon", 
        "Yahoo!ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚° ãƒ©ãƒ³ã‚­ãƒ³ã‚° ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  é›‘è²¨ -æ¥½å¤©å¸‚å ´ -Amazon" 
    ]
    results = []
    for q in queries:
        # æ¯ä¸ªæŸ¥è¯¢åªå– 1 æ¡ï¼Œä¿è¯æœ€é«˜çš„ç²¾å‡†åº¦
        results.extend(fetch_google_news_rss(q, limit=1))
    return results[:5]


# --- 5. æ—¥æœ¬å®æ—¶æ–°é—» (10æ¡, ç¡®ä¿ç¿»è¯‘) ---
def get_japan_real_time_news():
    print(f"æ­£åœ¨è·å–æ—¥æœ¬å®æ—¶æ–°é—» ({JAPAN_NEWS_LIMIT}æ¡)...")
    # æœç´¢æœ€æ–°çš„æ—¥æœ¬å›½å†…æ–°é—»ï¼Œç¡®ä¿æ•°é‡ä¸º 10
    return fetch_google_news_rss("æ—¥æœ¬ å›½å†… ãƒ‹ãƒ¥ãƒ¼ã‚¹ æœ€æ–°", limit=JAPAN_NEWS_LIMIT)

# ================= é£ä¹¦å‘é€å‡½æ•° =================

def send_feishu_card(webhook_url, data):
    """
    å‘é€é£ä¹¦å¯Œæ–‡æœ¬å¡ç‰‡æ¶ˆæ¯
    """
    today = datetime.datetime.now().strftime("%Y-%m-%d")
    template_color = "blue" 
    
    # è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆåˆ—è¡¨æ–‡æœ¬ (å…³é”®ï¼šå¼ºåˆ¶æ˜¾ç¤ºä¸­æ–‡ï¼Œæ—¥æ–‡/è‹±æ–‡ä½œä¸ºé“¾æ¥æ–‡æœ¬)
    def make_list_text(items, is_translated=True):
        if not items:
            return "æš‚æ— æ•°æ®æ›´æ–°æˆ–æŠ“å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥å…³é”®è¯æˆ–ç¨åé‡è¯•ã€‚"
        
        txt = ""
        for i, item in enumerate(items):
            link = item['link']
            title_jp = item['title_jp']
            
            if not is_translated:
                # çƒ­é—¨æ ‡ç­¾è¯ï¼Œåªæ˜¾ç¤ºæ—¥æ–‡/è‹±æ–‡åŸæ–‡ä½œä¸ºé“¾æ¥æ–‡æœ¬
                txt += f"{i+1}. [{title_jp}]({link})\n"
            else:
                # å…¶ä»–æ‰€æœ‰æ¿å—ï¼šå¼ºåˆ¶æ˜¾ç¤ºä¸­æ–‡ç¿»è¯‘ä½œä¸ºæ ‡é¢˜ï¼Œæ—¥æ–‡åŸæ–‡ä½œä¸ºé“¾æ¥æ–‡æœ¬
                title_display = item['title_cn'] if item['title_cn'] else "ç¿»è¯‘å¤±è´¥å†…å®¹"
                
                # å…³é”®ï¼š**ä¸­æ–‡æ ‡é¢˜** ç¡®ä¿äº†åŠ ç²—å’Œçªå‡ºï¼Œè§£å†³äº†æ‚¨æˆªå›¾ä¸­çš„é—®é¢˜
                txt += f"{i+1}. **{title_display}** [æ—¥æ–‡åŸæ–‡]({link})\n"
                
        return txt

    # --- ç»„è£…å†…å®¹ ---
    elements = []
    
    # 1. æ—¥æœ¬ TikTok æ˜¨æ—¥é”€é‡æ¦œå• (Top 1)
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "ğŸ”¥ **1. æ—¥æœ¬ TikTok Shop æ˜¨æ—¥é”€é‡æ¦œå• (5æ¡)**"}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": f"ğŸ‘‰ **[ç‚¹å‡»ç›´è¾¾ FastMoss é”€é‡æ¦œå• (æ— éœ€ç™»å½•)]({TIKTOK_SALES_LINK})**\n*(ä»¥ä¸‹ä¸ºç›¸å…³çƒ­é”€å“ç±»å’Œè¶‹åŠ¿èµ„è®¯ï¼Œå·²ç¿»è¯‘)*"}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": make_list_text(data['tiktok_sales'], is_translated=True)}})
    elements.append({"tag": "hr"}) 

    # 2. æ—¥æœ¬ TikTok çƒ­é—¨æ ‡ç­¾è¯ (Top 2)
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "ğŸµ **2. æ—¥æœ¬ TikTok çƒ­é—¨æ ‡ç­¾è¯ (Hashtag Trends - 5æ¡)**"}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": make_list_text(data['tiktok_hashtag'], is_translated=False)}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "*(æ³¨: æ ‡ç­¾è¯ä¿æŒæ—¥æ–‡/è‹±æ–‡åŸæ–‡ï¼Œç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…)*"}})
    elements.append({"tag": "hr"})

    # 3. æ—¥æœ¬ä¹å¤© (Rakuten) ç²¾é€‰æ¦œå• (Top 3)
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "ğŸ”´ **3. æ—¥æœ¬ä¹å¤© (Rakuten) ç²¾é€‰æ¦œå•å…³é”®è¯ (5æ¡)**"}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": make_list_text(data['rakuten_ranking'], is_translated=True)}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "*(æ³¨: æœç´¢ç»“æœä¸ºä¹å¤© Top å•†å“å…³é”®è¯ï¼Œå·²ç¿»è¯‘)*"}})
    elements.append({"tag": "hr"})

    # 4. æ—¥æœ¬é›…è™è´­ç‰© (Yahoo! Shopping) ç²¾é€‰æ¦œå• (Top 4)
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "ğŸŸ¢ **4. æ—¥æœ¬é›…è™è´­ç‰© (Yahoo! Shopping) ç²¾é€‰æ¦œå•å…³é”®è¯ (5æ¡)**"}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": make_list_text(data['yahoo_ranking'], is_translated=True)}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "*(æ³¨: æœç´¢ç»“æœä¸ºé›…è™è´­ç‰© Top å•†å“å…³é”®è¯ï¼Œå·²ç¿»è¯‘)*"}})
    elements.append({"tag": "hr"})
    
    # 5. æ—¥æœ¬å®æ—¶æ–°é—» (Top 5)
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "ğŸ“° **5. æ—¥æœ¬å›½å†…å®æ—¶æ–°é—» (10æ¡)**"}})
    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": make_list_text(data['japan_news'], is_translated=True)}})


    # --- ç»„è£…æœ€ç»ˆ JSON ---
    card_content = {
        "msg_type": "interactive",
        "card": {
            "header": {
                "title": {
                    "tag": "plain_text",
                    "content": f"ğŸ‡¯ğŸ‡µ æ—¥æœ¬ç”µå•†é€‰å“æ—©æŠ¥ ({today}) - å…¨çƒè´­åŠ©æ‰‹"
                },
                "template": template_color 
            },
            "elements": elements
        }
    }

    headers = {'Content-Type': 'application/json'}
    
    try:
        res = requests.post(webhook_url, headers=headers, data=json.dumps(card_content))
        print(f"å‘é€çŠ¶æ€: {res.status_code}, å“åº”: {res.text}")
    except Exception as e:
        print(f"å‘é€å¤±è´¥: {e}")

# ================= ä¸»ç¨‹åº =================

def main():
    if not FEISHU_WEBHOOK_URL:
        print("é”™è¯¯: æœªè®¾ç½®é£ä¹¦ Webhook URL")
        return

    # 1. è·å–å„é¡¹æ•°æ®
    data = {}
    
    # Top 1: TikTok é”€é‡æ¦œå• (èµ„è®¯ï¼Œæ•°é‡ 5)
    data["tiktok_sales"] = get_tiktok_sales_ranking()
    
    # Top 2: TikTok çƒ­é—¨æ ‡ç­¾è¯ (ä¸ç¿»è¯‘ï¼Œæ•°é‡ 5)
    data["tiktok_hashtag"] = get_tiktok_hashtag_trends()
    
    # Top 3: ä¹å¤©é”€é‡æ¦œå• (ç²¾å‡†å…³é”®è¯ï¼Œæ•°é‡ 5)
    data["rakuten_ranking"] = get_rakuten_ranking_info()
    
    # Top 4: é›…è™è´­ç‰©é”€é‡æ¦œå• (ç²¾å‡†å…³é”®è¯ï¼Œæ•°é‡ 5)
    data["yahoo_ranking"] = get_yahoo_ranking_info()
    
    # Top 5: æ—¥æœ¬å®æ—¶æ–°é—» (10æ¡)
    data["japan_news"] = get_japan_real_time_news()


    # 2. å‘é€
    send_feishu_card(FEISHU_WEBHOOK_URL, data)

if __name__ == "__main__":
    main()
